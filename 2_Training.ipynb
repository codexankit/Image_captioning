{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxLi5jEEFkHJ"
      },
      "source": [
        "## Project: Image Captioning\n",
        "#####Author: Ankit Kumar Prem\n",
        "---\n",
        "\n",
        "In this notebook, we will train our CNN-RNN model.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgIdIG5RFkHQ",
        "outputId": "6dadf754-757d-425b-8136-7d69bd66f516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary successfully loaded from vocab.pkl file!\n",
            "loading annotations into memory...\n",
            "Done (t=0.88s)\n",
            "creating index...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 775/414113 [00:00<01:51, 3700.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "index created!\n",
            "Obtaining caption lengths...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 414113/414113 [01:33<00:00, 4431.79it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import sys\n",
        "sys.path.append('/opt/cocoapi/PythonAPI')\n",
        "from pycocotools.coco import COCO\n",
        "from data_loader import get_loader\n",
        "from model import EncoderCNN, DecoderRNN\n",
        "import math\n",
        "\n",
        "\n",
        "## TODO #1: Select appropriate values for the Python variables below.\n",
        "batch_size = 128          # batch size\n",
        "vocab_threshold = 5        # minimum word count threshold\n",
        "vocab_from_file = True    # if True, load existing vocab file\n",
        "embed_size = 256           # dimensionality of image and word embeddings\n",
        "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
        "num_epochs = 3            # number of training epochs\n",
        "save_every = 1             # determines frequency of saving model weights\n",
        "print_every = 100          # determines window for printing average loss\n",
        "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
        "\n",
        "# (Optional) TODO #2: Amend the image transform below.\n",
        "transform_train = transforms.Compose([ \n",
        "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
        "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
        "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
        "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
        "                         (0.229, 0.224, 0.225))])\n",
        "\n",
        "# Build data loader.\n",
        "data_loader = get_loader(transform=transform_train,\n",
        "                         mode='train',\n",
        "                         batch_size=batch_size,\n",
        "                         vocab_threshold=vocab_threshold,\n",
        "                         vocab_from_file=vocab_from_file)\n",
        "\n",
        "# The size of the vocabulary.\n",
        "vocab_size = len(data_loader.dataset.vocab)\n",
        "\n",
        "# Initialize the encoder and decoder. \n",
        "encoder = EncoderCNN(embed_size)\n",
        "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
        "\n",
        "# Move models to GPU if CUDA is available. \n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "# Define the loss function. \n",
        "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
        "\n",
        "# TODO #3: Specify the learnable parameters of the model.\n",
        "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
        "\n",
        "# TODO #4: Define the optimizer.\n",
        "optimizer = torch.optim.Adam(params, lr=0.001)\n",
        "\n",
        "# Set the total number of training steps per epoch.\n",
        "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCcdYAgdFkHT"
      },
      "source": [
        "\n",
        " ### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89e6Tk4oFkHT",
        "outputId": "070a0f67-ac4a-46d6-ce4d-7774ac46234b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Step [100/3236], Loss: 3.6411, Perplexity: 38.1340\n",
            "Epoch [1/3], Step [200/3236], Loss: 3.6193, Perplexity: 37.3107\n",
            "Epoch [1/3], Step [300/3236], Loss: 3.2922, Perplexity: 26.9011\n",
            "Epoch [1/3], Step [400/3236], Loss: 3.1382, Perplexity: 23.06264\n",
            "Epoch [1/3], Step [500/3236], Loss: 2.9892, Perplexity: 19.8691\n",
            "Epoch [1/3], Step [600/3236], Loss: 2.8125, Perplexity: 16.6521\n",
            "Epoch [1/3], Step [700/3236], Loss: 3.1351, Perplexity: 22.9916\n",
            "Epoch [1/3], Step [800/3236], Loss: 2.7471, Perplexity: 15.5967\n",
            "Epoch [1/3], Step [900/3236], Loss: 2.6735, Perplexity: 14.4907\n",
            "Epoch [1/3], Step [1000/3236], Loss: 2.6453, Perplexity: 14.0872\n",
            "Epoch [1/3], Step [1100/3236], Loss: 2.7645, Perplexity: 15.8717\n",
            "Epoch [1/3], Step [1200/3236], Loss: 2.5515, Perplexity: 12.8267\n",
            "Epoch [1/3], Step [1300/3236], Loss: 2.4319, Perplexity: 11.3806\n",
            "Epoch [1/3], Step [1400/3236], Loss: 2.6811, Perplexity: 14.6017\n",
            "Epoch [1/3], Step [1500/3236], Loss: 2.4093, Perplexity: 11.1265\n",
            "Epoch [1/3], Step [1600/3236], Loss: 2.3140, Perplexity: 10.1148\n",
            "Epoch [1/3], Step [1700/3236], Loss: 2.2153, Perplexity: 9.16425\n",
            "Epoch [1/3], Step [1800/3236], Loss: 2.4575, Perplexity: 11.6758\n",
            "Epoch [1/3], Step [1900/3236], Loss: 2.4221, Perplexity: 11.2695\n",
            "Epoch [1/3], Step [2000/3236], Loss: 2.4513, Perplexity: 11.6035\n",
            "Epoch [1/3], Step [2100/3236], Loss: 2.3559, Perplexity: 10.5481\n",
            "Epoch [1/3], Step [2200/3236], Loss: 2.2299, Perplexity: 9.29878\n",
            "Epoch [1/3], Step [2300/3236], Loss: 3.0890, Perplexity: 21.9553\n",
            "Epoch [1/3], Step [2400/3236], Loss: 2.1395, Perplexity: 8.49505\n",
            "Epoch [1/3], Step [2500/3236], Loss: 2.4583, Perplexity: 11.6854\n",
            "Epoch [1/3], Step [2600/3236], Loss: 2.0679, Perplexity: 7.90836\n",
            "Epoch [1/3], Step [2700/3236], Loss: 2.1774, Perplexity: 8.82302\n",
            "Epoch [1/3], Step [2800/3236], Loss: 2.3991, Perplexity: 11.0132\n",
            "Epoch [1/3], Step [2900/3236], Loss: 2.3049, Perplexity: 10.0236\n",
            "Epoch [1/3], Step [3000/3236], Loss: 2.2071, Perplexity: 9.08892\n",
            "Epoch [1/3], Step [3100/3236], Loss: 2.7038, Perplexity: 14.9365\n",
            "Epoch [1/3], Step [3200/3236], Loss: 2.2487, Perplexity: 9.47541\n",
            "Epoch [2/3], Step [100/3236], Loss: 2.3916, Perplexity: 10.93057\n",
            "Epoch [2/3], Step [200/3236], Loss: 2.0698, Perplexity: 7.92306\n",
            "Epoch [2/3], Step [300/3236], Loss: 2.3206, Perplexity: 10.1815\n",
            "Epoch [2/3], Step [400/3236], Loss: 2.2225, Perplexity: 9.23074\n",
            "Epoch [2/3], Step [500/3236], Loss: 2.0949, Perplexity: 8.12444\n",
            "Epoch [2/3], Step [600/3236], Loss: 2.3916, Perplexity: 10.9308\n",
            "Epoch [2/3], Step [700/3236], Loss: 2.5551, Perplexity: 12.8720\n",
            "Epoch [2/3], Step [800/3236], Loss: 2.1856, Perplexity: 8.89581\n",
            "Epoch [2/3], Step [900/3236], Loss: 2.2322, Perplexity: 9.32020\n",
            "Epoch [2/3], Step [1000/3236], Loss: 2.0706, Perplexity: 7.9295\n",
            "Epoch [2/3], Step [1100/3236], Loss: 1.9134, Perplexity: 6.77638\n",
            "Epoch [2/3], Step [1200/3236], Loss: 2.1265, Perplexity: 8.38514\n",
            "Epoch [2/3], Step [1300/3236], Loss: 2.2359, Perplexity: 9.35506\n",
            "Epoch [2/3], Step [1400/3236], Loss: 2.6097, Perplexity: 13.5952\n",
            "Epoch [2/3], Step [1500/3236], Loss: 2.1717, Perplexity: 8.77368\n",
            "Epoch [2/3], Step [1600/3236], Loss: 1.9846, Perplexity: 7.27658\n",
            "Epoch [2/3], Step [1700/3236], Loss: 2.0481, Perplexity: 7.75289\n",
            "Epoch [2/3], Step [1800/3236], Loss: 2.0526, Perplexity: 7.78806\n",
            "Epoch [2/3], Step [1900/3236], Loss: 2.0880, Perplexity: 8.06843\n",
            "Epoch [2/3], Step [2000/3236], Loss: 2.1356, Perplexity: 8.46240\n",
            "Epoch [2/3], Step [2100/3236], Loss: 1.9854, Perplexity: 7.28219\n",
            "Epoch [2/3], Step [2200/3236], Loss: 2.0708, Perplexity: 7.931499\n",
            "Epoch [2/3], Step [2300/3236], Loss: 2.0560, Perplexity: 7.81486\n",
            "Epoch [2/3], Step [2400/3236], Loss: 2.0793, Perplexity: 7.99879\n",
            "Epoch [2/3], Step [2500/3236], Loss: 2.0773, Perplexity: 7.98257\n",
            "Epoch [2/3], Step [2600/3236], Loss: 2.1911, Perplexity: 8.94502\n",
            "Epoch [2/3], Step [2700/3236], Loss: 2.0368, Perplexity: 7.66641\n",
            "Epoch [2/3], Step [2800/3236], Loss: 1.9699, Perplexity: 7.16970\n",
            "Epoch [2/3], Step [2900/3236], Loss: 2.0212, Perplexity: 7.54725\n",
            "Epoch [2/3], Step [3000/3236], Loss: 1.9691, Perplexity: 7.16454\n",
            "Epoch [2/3], Step [3100/3236], Loss: 2.2134, Perplexity: 9.14654\n",
            "Epoch [2/3], Step [3200/3236], Loss: 2.2947, Perplexity: 9.92132\n",
            "Epoch [3/3], Step [100/3236], Loss: 1.9663, Perplexity: 7.144065\n",
            "Epoch [3/3], Step [200/3236], Loss: 2.0037, Perplexity: 7.41666\n",
            "Epoch [3/3], Step [300/3236], Loss: 2.0702, Perplexity: 7.92648\n",
            "Epoch [3/3], Step [400/3236], Loss: 2.0093, Perplexity: 7.45800\n",
            "Epoch [3/3], Step [500/3236], Loss: 1.9592, Perplexity: 7.09380\n",
            "Epoch [3/3], Step [600/3236], Loss: 1.9787, Perplexity: 7.23317\n",
            "Epoch [3/3], Step [700/3236], Loss: 1.8924, Perplexity: 6.63518\n",
            "Epoch [3/3], Step [800/3236], Loss: 1.9421, Perplexity: 6.97376\n",
            "Epoch [3/3], Step [900/3236], Loss: 1.9100, Perplexity: 6.75342\n",
            "Epoch [3/3], Step [1000/3236], Loss: 2.3389, Perplexity: 10.3703\n",
            "Epoch [3/3], Step [1100/3236], Loss: 1.9779, Perplexity: 7.22738\n",
            "Epoch [3/3], Step [1200/3236], Loss: 1.9471, Perplexity: 7.00805\n",
            "Epoch [3/3], Step [1300/3236], Loss: 1.9220, Perplexity: 6.83475\n",
            "Epoch [3/3], Step [1400/3236], Loss: 2.2895, Perplexity: 9.86996\n",
            "Epoch [3/3], Step [1500/3236], Loss: 1.9851, Perplexity: 7.27986\n",
            "Epoch [3/3], Step [1600/3236], Loss: 1.9800, Perplexity: 7.24298\n",
            "Epoch [3/3], Step [1700/3236], Loss: 1.8756, Perplexity: 6.52455\n",
            "Epoch [3/3], Step [1800/3236], Loss: 1.9858, Perplexity: 7.28527\n",
            "Epoch [3/3], Step [1900/3236], Loss: 2.1598, Perplexity: 8.66913\n",
            "Epoch [3/3], Step [2000/3236], Loss: 1.9298, Perplexity: 6.88833\n",
            "Epoch [3/3], Step [2100/3236], Loss: 1.9020, Perplexity: 6.69957\n",
            "Epoch [3/3], Step [2200/3236], Loss: 2.4599, Perplexity: 11.70389\n",
            "Epoch [3/3], Step [2300/3236], Loss: 2.0045, Perplexity: 7.42240\n",
            "Epoch [3/3], Step [2400/3236], Loss: 2.1457, Perplexity: 8.54770\n",
            "Epoch [3/3], Step [2500/3236], Loss: 1.8744, Perplexity: 6.51706\n",
            "Epoch [3/3], Step [2600/3236], Loss: 1.9031, Perplexity: 6.70699\n",
            "Epoch [3/3], Step [2700/3236], Loss: 1.9109, Perplexity: 6.75933\n",
            "Epoch [3/3], Step [2800/3236], Loss: 1.9221, Perplexity: 6.83549\n",
            "Epoch [3/3], Step [2900/3236], Loss: 1.9993, Perplexity: 7.38375\n",
            "Epoch [3/3], Step [3000/3236], Loss: 1.9375, Perplexity: 6.94124\n",
            "Epoch [3/3], Step [3100/3236], Loss: 1.9567, Perplexity: 7.07572\n",
            "Epoch [3/3], Step [3200/3236], Loss: 1.8485, Perplexity: 6.35005\n",
            "Epoch [3/3], Step [3236/3236], Loss: 1.8586, Perplexity: 6.41491"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Open the training log file.\n",
        "f = open(log_file, 'w')\n",
        "\n",
        "old_time = time.time()\n",
        "response = requests.request(\"GET\", \n",
        "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
        "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    \n",
        "    for i_step in range(1, total_step+1):\n",
        "        \n",
        "        if time.time() - old_time > 60:\n",
        "            old_time = time.time()\n",
        "            requests.request(\"POST\", \n",
        "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
        "                             headers={'Authorization': \"STAR \" + response.text})\n",
        "        \n",
        "        # Randomly sample a caption length, and sample indices with that length.\n",
        "        indices = data_loader.dataset.get_train_indices()\n",
        "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
        "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
        "        data_loader.batch_sampler.sampler = new_sampler\n",
        "        \n",
        "        # Obtain the batch.\n",
        "        images, captions = next(iter(data_loader))\n",
        "\n",
        "        # Move batch of images and captions to GPU if CUDA is available.\n",
        "        images = images.to(device)\n",
        "        captions = captions.to(device)\n",
        "        \n",
        "        # Zero the gradients.\n",
        "        decoder.zero_grad()\n",
        "        encoder.zero_grad()\n",
        "        \n",
        "        # Pass the inputs through the CNN-RNN model.\n",
        "        features = encoder(images)\n",
        "        outputs = decoder(features, captions)\n",
        "        \n",
        "        # Calculate the batch loss.\n",
        "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
        "        \n",
        "        # Backward pass.\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the parameters in the optimizer.\n",
        "        optimizer.step()\n",
        "            \n",
        "        # Get training statistics.\n",
        "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
        "        \n",
        "        # Print training statistics (on same line).\n",
        "        print('\\r' + stats, end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "        # Print training statistics to file.\n",
        "        f.write(stats + '\\n')\n",
        "        f.flush()\n",
        "        \n",
        "        # Print training statistics (on different line).\n",
        "        if i_step % print_every == 0:\n",
        "            print('\\r' + stats)\n",
        "            \n",
        "    # Save the weights.\n",
        "    if epoch % save_every == 0:\n",
        "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
        "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
        "\n",
        "# Close the training log file.\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}